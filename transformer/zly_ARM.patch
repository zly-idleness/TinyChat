diff --git a/kernels/starter_code/all_techniques.cc b/kernels/starter_code/all_techniques.cc
index c902e7e..c3307ec 100644
--- a/kernels/starter_code/all_techniques.cc
+++ b/kernels/starter_code/all_techniques.cc
@@ -66,11 +66,33 @@ static void *all_techniques_worker_func(void *args) {
                 // (3) use `vreinterpretq_s8_u8` to interpret the  vector as int8
                 // lowbit mask
                 const uint8x16_t mask_low4bit = vdupq_n_u8(0xf);
-
+                uint8x16_t w0_l = vandq_u8(w0, mask_low4bit);
+                uint8x16_t w0_h = vshrq_n_u8(w0, 4);
+                uint8x16_t w1_l = vandq_u8(w1, mask_low4bit);
+                uint8x16_t w1_h = vshrq_n_u8(w1, 4);
+                uint8x16_t w2_l = vandq_u8(w2, mask_low4bit);
+                uint8x16_t w2_h = vshrq_n_u8(w2, 4);
+                uint8x16_t w3_l = vandq_u8(w3, mask_low4bit);
+                uint8x16_t w3_h = vshrq_n_u8(w3, 4);
+                int8x16_t w0_l_int8 = vreinterpretq_s8_u8(w0_l);
+                int8x16_t w0_h_int8 = vreinterpretq_s8_u8(w0_h);
+                int8x16_t w1_l_int8 = vreinterpretq_s8_u8(w1_l);
+                int8x16_t w1_h_int8 = vreinterpretq_s8_u8(w1_h);
+                int8x16_t w2_l_int8 = vreinterpretq_s8_u8(w2_l);
+                int8x16_t w2_h_int8 = vreinterpretq_s8_u8(w2_h);
+                int8x16_t w3_l_int8 = vreinterpretq_s8_u8(w3_l);
+                int8x16_t w3_h_int8 = vreinterpretq_s8_u8(w3_h);
                 // TODO: apply zero_point to weights and convert the range from (0, 15) to (-8, 7)
                 // Hint: using `vsubq_s8` to the lower-half and upper-half vectors of weights
                 const int8x16_t offsets = vdupq_n_s8(8);
-
+                w0_l_int8 = vsubq_s8(w0_l_int8, offsets);
+                w0_h_int8 = vsubq_s8(w0_h_int8, offsets);
+                w1_l_int8 = vsubq_s8(w1_l_int8, offsets);
+                w1_h_int8 = vsubq_s8(w1_h_int8, offsets);
+                w2_l_int8 = vsubq_s8(w2_l_int8, offsets);
+                w2_h_int8 = vsubq_s8(w2_h_int8, offsets);
+                w3_l_int8 = vsubq_s8(w3_l_int8, offsets);
+                w3_h_int8 = vsubq_s8(w3_h_int8, offsets);
                 // load 128 8-bit activation
                 const int8x16_t a0 = vld1q_s8(a_start);
                 const int8x16_t a1 = vld1q_s8(a_start + 16);
@@ -86,6 +108,20 @@ static void *all_techniques_worker_func(void *args) {
                 // Hint: use `vdotq_s32` and store the sum for each block in int_sum{0-3}
                 int32x4_t int_sum0, int_sum1, int_sum2, int_sum3;
 
+                int32x4_t tmp_1;
+                int32x4_t tmp_2;
+                int_sum0 = vdotq_s32(tmp_1, a0, w0_l_int8);
+                int_sum0 += vdotq_s32(tmp_2, a1, w0_h_int8);
+
+                int_sum1 = vdotq_s32(tmp_1, a2, w1_l_int8);
+                int_sum1 += vdotq_s32(tmp_2, a3, w1_h_int8);
+
+                int_sum2 = vdotq_s32(tmp_1, a4, w2_l_int8);
+                int_sum2 += vdotq_s32(tmp_2, a5, w2_h_int8);
+
+                int_sum3 = vdotq_s32(tmp_1, a6, w3_l_int8);
+                int_sum3 += vdotq_s32(tmp_2, a7, w3_h_int8);
+
                 float s_0 = *s_a++ * *s_w++;
                 float s_1 = *s_a++ * *s_w++;
                 float s_2 = *s_a++ * *s_w++;
@@ -221,8 +257,25 @@ void MatmulOperator::mat_mul_all_techniques(struct matmul_params *params) {
     struct w4a8_thread_args threads_args[num_thread];
     assert(params->block_size == 32);  // support block size 32 for now
 
-    // TODO: Thread creation
+    // Calculate the number of columns each thread will process
 
-    // TODO: Join threads
+    int m = C->row, n = C->column;
+    int cols_per_thread = n / num_thread;
+    // Create threads
+    for (int i = 0; i < num_thread; i++) {
+        int start_col = i * cols_per_thread;
+        int end_col = (i == num_thread - 1) ? n : (i + 1) * cols_per_thread;
+
+        threads_args[i].start_j = start_col;
+        threads_args[i].end_j = end_col;
+        threads_args[i].params = params;
+
+        pthread_create(&thread_pool[i], NULL, all_techniques_worker_func, (void *)&threads_args[i]);
+    }
+
+    // Join threads
+    for (int i = 0; i < num_thread; i++) {
+        pthread_join(thread_pool[i], NULL);
+    }
 };
 }  // namespace matmul
diff --git a/kernels/starter_code/loop_unrolling.cc b/kernels/starter_code/loop_unrolling.cc
index f64a536..0006fc3 100644
--- a/kernels/starter_code/loop_unrolling.cc
+++ b/kernels/starter_code/loop_unrolling.cc
@@ -55,8 +55,28 @@ void MatmulOperator::mat_mul_loop_unrolling(struct matmul_params *params) {
                 int intermediate_sum0 = 0, intermediate_sum1 = 0, intermediate_sum2 = 0, intermediate_sum3 = 0;
                 for (int qj = 0; qj < 16; qj++) {
                     // TODO: decode a packed byte into two int8 in the range of (-8, 7)
+                    uint8_t packed_int4_0 = w0_int4[qj];
+                    uint8_t packed_int4_1 = w1_int4[qj];
+                    uint8_t packed_int4_2 = w2_int4[qj];
+                    uint8_t packed_int4_3 = w3_int4[qj];
+                    signed char w_de_0 = (packed_int4_0 & 0x0F) - 8.0;
+                    signed char w_de_16 = (packed_int4_0 >> 4) - 8.0;
+                    signed char w_de_1 = (packed_int4_1 & 0x0F) - 8.0;
+                    signed char w_de_17 = (packed_int4_1 >> 4) - 8.0;
+                    signed char w_de_2 = (packed_int4_2 & 0x0F) - 8.0;
+                    signed char w_de_18 = (packed_int4_2 >> 4) - 8.0;
+                    signed char w_de_3 = (packed_int4_3 & 0x0F) - 8.0;
+                    signed char w_de_19 = (packed_int4_3 >> 4) - 8.0;
 
                     // TODO: int8 multiply and accumulate operation
+                    intermediate_sum0 += a_int8[qj] * w_de_0;
+                    intermediate_sum0 += a_int8[qj + 16] * w_de_16;
+                    intermediate_sum1 += a_int8[qj] * w_de_1;
+                    intermediate_sum1 += a_int8[qj + 16] * w_de_17;
+                    intermediate_sum2 += a_int8[qj] * w_de_2;
+                    intermediate_sum2 += a_int8[qj + 16] * w_de_18;
+                    intermediate_sum3 += a_int8[qj] * w_de_3;
+                    intermediate_sum3 += a_int8[qj + 16] * w_de_19;
                 }
                 // dequantize the sum into floating point
                 acc0 += (float)intermediate_sum0 * s_a * s_w0;
diff --git a/kernels/starter_code/multithreading.cc b/kernels/starter_code/multithreading.cc
index ffc540a..ae33949 100644
--- a/kernels/starter_code/multithreading.cc
+++ b/kernels/starter_code/multithreading.cc
@@ -96,6 +96,8 @@ static void* multithreading_worker_func(void* args) {
     return NULL;
 }
 
+#include <vector>
+
 namespace matmul {
 void MatmulOperator::mat_mul_multithreading(struct matmul_params* params) {
     const struct matrix *A = &params->A, *B = &params->B, *C = &params->C;
@@ -109,8 +111,24 @@ void MatmulOperator::mat_mul_multithreading(struct matmul_params* params) {
     pthread_t thread_pool[num_thread];
     struct multithreading_thread_args threads_args[num_thread];
 
-    // TODO: Thread creation
+    // Calculate the number of columns each thread will process
+    int cols_per_thread = n / num_thread;
+
+    // Create threads
+    for (int i = 0; i < num_thread; i++) {
+        int start_col = i * cols_per_thread;
+        int end_col = (i == num_thread - 1) ? n : (i + 1) * cols_per_thread;
+
+        threads_args[i].start = start_col;
+        threads_args[i].end = end_col;
+        threads_args[i].params = params;
 
-    // TODO: Join threads
+        pthread_create(&thread_pool[i], NULL, multithreading_worker_func, (void*)&threads_args[i]);
+    }
+
+    // Join threads
+    for (int i = 0; i < num_thread; i++) {
+        pthread_join(thread_pool[i], NULL);
+    }
 };
 }  // namespace matmul
diff --git a/kernels/starter_code/multithreading_loop_unrolling.cc b/kernels/starter_code/multithreading_loop_unrolling.cc
index 4a3b014..68f9bff 100644
--- a/kernels/starter_code/multithreading_loop_unrolling.cc
+++ b/kernels/starter_code/multithreading_loop_unrolling.cc
@@ -56,9 +56,28 @@ static void *multithreading_loop_unrolling_worker_func(void *args) {
                 // intermediate variable to store sum of integer multiplication and accumulation
                 int intermediate_sum0 = 0, intermediate_sum1 = 0, intermediate_sum2 = 0, intermediate_sum3 = 0;
                 for (int qj = 0; qj < 16; qj++) {
-                    // TODO: decode a packed byte into two int8 in the range of (-8, 7)
+                    uint8_t packed_int4_0 = w0_int4[qj];
+                    uint8_t packed_int4_1 = w1_int4[qj];
+                    uint8_t packed_int4_2 = w2_int4[qj];
+                    uint8_t packed_int4_3 = w3_int4[qj];
+                    signed char w_de_0 = (packed_int4_0 & 0x0F) - 8.0;
+                    signed char w_de_16 = (packed_int4_0 >> 4) - 8.0;
+                    signed char w_de_1 = (packed_int4_1 & 0x0F) - 8.0;
+                    signed char w_de_17 = (packed_int4_1 >> 4) - 8.0;
+                    signed char w_de_2 = (packed_int4_2 & 0x0F) - 8.0;
+                    signed char w_de_18 = (packed_int4_2 >> 4) - 8.0;
+                    signed char w_de_3 = (packed_int4_3 & 0x0F) - 8.0;
+                    signed char w_de_19 = (packed_int4_3 >> 4) - 8.0;
 
                     // TODO: int8 multiply and accumulate operation
+                    intermediate_sum0 += a_int8[qj] * w_de_0;
+                    intermediate_sum0 += a_int8[qj + 16] * w_de_16;
+                    intermediate_sum1 += a_int8[qj] * w_de_1;
+                    intermediate_sum1 += a_int8[qj + 16] * w_de_17;
+                    intermediate_sum2 += a_int8[qj] * w_de_2;
+                    intermediate_sum2 += a_int8[qj + 16] * w_de_18;
+                    intermediate_sum3 += a_int8[qj] * w_de_3;
+                    intermediate_sum3 += a_int8[qj + 16] * w_de_19;
                 }
                 // dequantize the sum into floating point
                 acc0 += (float)intermediate_sum0 * s_a * s_w0;
@@ -130,8 +149,24 @@ void MatmulOperator::mat_mul_multithreading_loop_unrolling(struct matmul_params
     struct multithreading_loop_unrolling_thread_args threads_args[num_thread];
     assert(params->block_size == 32);  // support block size 32 for now
 
-    // TODO: Thread creation
+    // Calculate the number of columns each thread will process
+    int cols_per_thread = n / num_thread;
+
+    // Create threads
+    for (int i = 0; i < num_thread; i++) {
+        int start_col = i * cols_per_thread;
+        int end_col = (i == num_thread - 1) ? n : (i + 1) * cols_per_thread;
+
+        threads_args[i].start = start_col;
+        threads_args[i].end = end_col;
+        threads_args[i].params = params;
 
-    // TODO: Join threads
+        pthread_create(&thread_pool[i], NULL, multithreading_loop_unrolling_worker_func, (void *)&threads_args[i]);
+    }
+
+    // Join threads
+    for (int i = 0; i < num_thread; i++) {
+        pthread_join(thread_pool[i], NULL);
+    }
 };
 }  // namespace matmul
diff --git a/kernels/starter_code/simd_programming.cc b/kernels/starter_code/simd_programming.cc
index a65c48a..80d5269 100644
--- a/kernels/starter_code/simd_programming.cc
+++ b/kernels/starter_code/simd_programming.cc
@@ -60,14 +60,24 @@ void MatmulOperator::mat_mul_simd_programming(struct matmul_params *params) {
                 // Hint:
                 // (1) use `vandq_u8` with the mask_low4bit to get the lower half
                 // (2) use `vshrq_n_u8` to right shift 4 bits and get the upper half
-                // (3) use `vreinterpretq_s8_u8` to interpret the  vector as int8
+                // (3) use `vreinterpretq_s8_u8` to interpret the vector as int8
                 // lowbit mask
                 const uint8x16_t mask_low4bit = vdupq_n_u8(0xf);
 
+                // decode the lower and upper half of the weights
+                uint8x16_t weights_low = vandq_u8(w0, mask_low4bit);
+                uint8x16_t weights_high = vshrq_n_u8(w0, 0x4);
+                int8x16_t weights_low_int8 = vreinterpretq_s8_u8(weights_low);
+                int8x16_t weights_high_int8 = vreinterpretq_s8_u8(weights_high);
+
                 // TODO: apply zero_point to weights and convert the range from (0, 15) to (-8, 7)
                 // Hint: using `vsubq_s8` to the lower-half and upper-half vectors of weights
                 const int8x16_t offsets = vdupq_n_s8(8);
 
+                // sub 8
+                weights_low_int8 = vsubq_s8(weights_low_int8, offsets);
+                weights_high_int8 = vsubq_s8(weights_high_int8, offsets);
+
                 // load 32 8-bit activation
                 const int8x16_t a0 = vld1q_s8(a_start);
                 const int8x16_t a1 = vld1q_s8(a_start + 16);
@@ -77,7 +87,11 @@ void MatmulOperator::mat_mul_simd_programming(struct matmul_params *params) {
                 // Hint: use `vdotq_s32` to compute sumv0 = a0 * lower-half weights + a1 * upper-half weights
                 // int32x4 vector to store intermediate sum
                 int32x4_t int_sum0;
-
+                int32x4_t tmp_1;
+                int32x4_t tmp_2;
+                int_sum0 = vdotq_s32(tmp_1, a0, weights_low_int8);
+                int_sum0 += vdotq_s32(tmp_2, a1, weights_high_int8);
+                // int_sum0 = vaddq_s32(tmp_1, tmp_2);
                 float s_0 = *s_a++ * *s_w++;
                 sumv0 = vmlaq_n_f32(sumv0, vcvtq_f32_s32(int_sum0), s_0);
             }
